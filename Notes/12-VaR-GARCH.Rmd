It is not always straightforward to compute value-at-risk for GARCH models, though it should be. 

In the example below, I have taken the very nice examples 
of computing VaR in-sample and out-of-sample from the Ox G@RCH toolbox, and translated them into
R, and hopefully elucidating the logic.

Here is plot of the underlying NASDAQ returns series from "1984-10-12" to "2000-12-21".

``` {r prelim, echo=TRUE, include=FALSE, message=FALSE}
library(xlsx)
library(xts)
library(rugarch)
library(skewt)
library(reshape2)
library(ggplot2)
library(fGarch) # for standardized Student-t distribution quantiles

knitr::opts_knit$set(root.dir = "D:\\Projects\\RProjects\\Stackoverflow-R")
```

``` {r dataLoad}
# read in the data
dfN = read.xlsx("Data/nasdaq.xls", sheetIndex = 1)
xN = xts(dfN$Nasdaq, order.by = dfN$Date)            
plot(xN)
```

I fit an ARMA(2, 0)-APARCH(1, 1) model to the data with three different distributions:
* standard normal
* Student's t
* skewed Student's t
In each case I restrict the sample to the first day of 2000 only. 

``` {r modelFit}
#================================================
# compute the model fit
#================================================
# fit an ARMA(2, 0)-APARCH(1, 1) Normal model
gN1 = ugarchspec(variance.model = list(model = "apARCH",
                                 garchOrder = c(1, 1)), 
           mean.model = list(armaOrder = c(2, 0), 
                             include.mean = TRUE),
           distribution.model = "norm")
gfN1 = ugarchfit(gN1, data = xN["/2000-01-01"])

# fit an ARMA(2, 0)-APARCH(1, 1) skewed-Student model
gN2 = ugarchspec(variance.model = list(model = "apARCH",
                                       garchOrder = c(1, 1)), 
                 mean.model = list(armaOrder = c(2, 0), 
                                   include.mean = TRUE),
                 distribution.model = "sstd")
gfN2 = ugarchfit(gN2, data = xN["/2000-01-01"])

# fit an ARMA(2, 0)-APARCH(1, 1) Student-t model
gN3 = ugarchspec(variance.model = list(model = "apARCH",
                                       garchOrder = c(1, 1)), 
                 mean.model = list(armaOrder = c(2, 0), 
                                   include.mean = TRUE),
                 distribution.model = "std")
gfN3 = ugarchfit(gN3, data = xN["/2000-01-01"])
```

Then, I write a function to get the VaR for different distributions. Note that for this
I use the standardized quantile functions of the t- and skewed t- from the fGarch package. 

``` {r computeVaR}
#================================================
# function to compute VaR for different distributions
#================================================
getVaR = function(objGarchFit, vQ) {
  # get the distribution
  sDistrib = objGarchFit@model$modeldesc$distribution
  # get the conditional mean
  vCondMean = fitted(objGarchFit)
  # get the conditional s.d.
  vCondSD = sigma(objGarchFit)
  
  # pre-assign the return matrix
  mVaR = matrix(NA, nrow = objGarchFit@model$modeldata$T,
                 ncol = length(vQ))
  
  mVaR = switch(sDistrib, 
         norm = sapply(vQ, function(quantile) {
           vCondMean + vCondSD * qnorm(quantile)
         }),
         std = {
           dDoF = coef(objGarchFit)["shape"]
           sapply(vQ, function(quantile) {
               ## NOTE: The variance is finite for df > 2
               vCondMean + vCondSD * 
                   qstd(quantile, nu = dDoF) 
           })
         }, 
         sstd = {
           dDoF = coef(objGarchFit)["shape"]
           dGamma = coef(objGarchFit)["skew"]
           sapply(vQ, function(quantile) {
             ## NOTE: the variance is only finite for df > 4
               vCondMean + vCondSD *
                   qsstd(p = quantile, nu = dDoF, xi = dGamma)  
           })
       })
  colnames(mVaR) = paste0("VaR", vQ)
  rownames(mVaR) = as.character(objGarchFit@model$modeldata$index)
  return(mVaR)
}
```

Next, I use the function to compute the in-sample 90% VaR, and check the computations
by checking the number of times the series exceeds the VaR.

``` {r checkVaR, echo = TRUE, include = FALSE}
#================================================
# compute the in-sample VaR
#================================================
# get the in-sample VaR
mVaR1 = getVaR(gfN1, c(0.1, 0.9))
mVaR2 = getVaR(gfN2, c(0.1, 0.9))
mVaR3 = getVaR(gfN3, c(0.1, 0.9))

# check the VaR computations
mean(gfN2@model$modeldata$data > mVaR2[, 2])
mean(gfN2@model$modeldata$data < mVaR2[, 1])

mean(gfN1@model$modeldata$data > mVaR1[, 2])
mean(gfN1@model$modeldata$data < mVaR1[, 1])

mean(gfN3@model$modeldata$data > mVaR3[, 2])
mean(gfN3@model$modeldata$data < mVaR3[, 1])
```

Next, we can forecast the GARCH volatility using the following steps:
1. Compute the `n.ahead` forecast given the information today. 
2. Roll the forecast ahead by `n.roll`, and then compute `n.ahead` forecasts again.
3. Do this, till you run out of `out.sample`.
4. Now re-estimate the GARCH model upto the previous `out.sample`, and repeat above process. 

``` {r forecastGARCH} 
grN1 = ugarchroll(gN1, data = xN, n.ahead = 1, 
                  n.start = 4000, refit.every = 10, 
                  refit.window = "recursive", 
                  calculate.VaR = TRUE, VaR.alpha = c(0.01), 
                  keep.coef = FALSE)
```



  